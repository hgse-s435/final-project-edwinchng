{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**: describe your dataset, and why you're interested in it\n",
    "\n",
    "In this dataset, Kinect sensors captured students' body postures, location, and gestures in a makerspace over the period of a 13-weeks semester, recording nearly half a million observations from 16 students enrolled in a class. \n",
    "\n",
    "I am interested in this dataset because I am currently involved in the next iteration of the Makerspace project and it would be good to gain more familiarity with the dataset by analyzing it in this final project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research question(s)**: describe the overall research question of your project\n",
    "\n",
    "Can the activities of students be detected from their location and their body postures in the makerspace (e.g., using a laser cutter, interacting with someone, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypotheses**:\n",
    "    * Describe 2-3 hypotheses that you're planning to test with your dataset\n",
    "    * Each hypoteses should be based on academic research (cite a paper) and/or background knowledge that you have about the dataset if you've collected it yourself (e.g., if you've conducted interviews)\n",
    "    * Each hypotheses should be formulated as an affirmation (and not a question)\n",
    "    * You can also describe alternative hypotheses, if you think that your results could go either way (but again, have a rationale as for why)\n",
    "\n",
    "    \n",
    "**Hypothesis 1**\n",
    "Using the x-y coordinates of the head joint, the approximate position of students can be inferred, which then informs if they are using tools or working with others within the makerspace. \n",
    "\n",
    "**Hypothesis 2**\n",
    "Students who have joint line of sight with their partners indicates collaboration within the makerspace. \n",
    "\n",
    "**Papers**\n",
    "Hall, E. T. (1966). The Hidden Dimension. Anchor Books.\n",
    "\n",
    "Reilly, J.M. et al. Exploring Collaboration Using Motion Sensors and Multi-Modal Learning Analytics. Educational Data Mining Conference 2018.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**:\n",
    "    * how are you planning to test each hypothesis? What models are you thinking of using?\n",
    "I am planning to first derive features such as proximity, hand gesturing and line of sight of students to indicate the activities of students within the makerspace. Thereafter, I will train a machine learning algorithm based on these features to predict the activities of students. As a test of the accuracy of the algorithm, I will exclude one week of data during the training stage and test the algorithm later using this test set. For the test set, manual coding using video would be done to denote the activities of the students instead of using the generated features. \n",
    "\n",
    "\n",
    "    * what are the best results you can hope for? Is that interesting / relevant for other researchers?\n",
    "The best results would be a strong correlation between the generated features and student activities. This would be interesting for other researchers as the profiling of student activities could lead to other areas of research such as personalized interventions and quality of social interactions.\n",
    "\n",
    "    * what are implications of your potential findings for practioners? \n",
    "Students activities could be inferred from the generated features without the teachers having to pay continuous attention to each and every student within the makerspace. This presents practioners a way of understanding their students to cater to their individual learning needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Threads**\n",
    "    * Describe issues that might arise during the analyses above\n",
    "It might be possible that we may not derive features that can successfully predict the activities of students or we may also be looking at the incorrect features of the body movement to inform us of the activities of students.\n",
    "\n",
    "    * Come up with backup plans in case you run into theses issues\n",
    "Think of alternative features of the students' body movement or allow the models to uncover the relevant features without making any prior assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe your raw data below; provide definition / explanations for the measures you're using\n",
    "\n",
    "The raw data consists of student information (eg person_id, name), skeletal joint data, facial expressions (eg isTalking) and collection information (eg timestamp, kinect_id). For the purpose of this investigation, we will drop information mostly related to facial expressions as 1) these variables are dichotomous 2) they contain a limited range of facial expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean you data in this section, and make sure it's ready to be analyzed for next week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv']\n"
     ]
    }
   ],
   "source": [
    "# import files from directory\n",
    "\n",
    "import os\n",
    "\n",
    "files = []\n",
    "\n",
    "for file in os.listdir('./test'):\n",
    "    if file.endswith('.csv'):\n",
    "        files.append(file)\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'test',\n",
       " 'dataset',\n",
       " 'data_cleaned',\n",
       " 'Wee9-Final-Project.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " '.git']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new folder to store cleaned data\n",
    "\n",
    "os.mkdir('./data_cleaned')\n",
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv']\n"
     ]
    }
   ],
   "source": [
    "# clean data and output as csv to folder\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "instructor_list = ['sammie','othertwo','otherthree','name','yanni','carlie','billy',\n",
    "                   'othereight','otherfive','otherfour','otherone','otherseven','othersix']\n",
    "\n",
    "for file in os.listdir('./test'):\n",
    "    if file.endswith('.csv'):\n",
    "        file_input = os.path.join('./test',file)\n",
    "        df = pd.read_csv(file_input)\n",
    "        cleaned = df.drop([df.columns[0],'name_aga_conf','confidence_value','name_aga_freq','frequency','freq_count',\n",
    "                            'isWearingGlasses','isSmiling','leftHandRaised','rightHandRaised',\n",
    "                           'ip','et_timestamp','skeleton','person_id_lifespan','face_detected','timestamp'], axis=1)\n",
    "        cleaned.dropna(inplace=True)\n",
    "        \n",
    "        for name in instructor_list:\n",
    "            indexNames = cleaned[cleaned['weighted_name'] == name].index\n",
    "            cleaned.drop(indexNames,inplace=True)\n",
    "        \n",
    "        file_output = os.path.join('./data_cleaned',file)\n",
    "        cleaned.to_csv(file_output)\n",
    "        \n",
    "print(os.listdir('./data_cleaned'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis (Preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv']\n"
     ]
    }
   ],
   "source": [
    "# import files from directory\n",
    "\n",
    "import os\n",
    "\n",
    "files = []\n",
    "\n",
    "for file in os.listdir('./data_cleaned'):\n",
    "    if file.endswith('.csv'):\n",
    "        files.append(file)\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_analysis',\n",
       " '.DS_Store',\n",
       " 'test',\n",
       " 'dataset',\n",
       " 'data_cleaned',\n",
       " 'Wee9-Final-Project.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " '.git']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new folder to store data for analysis\n",
    "\n",
    "os.mkdir('./data_analysis')\n",
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44975, 32)\n"
     ]
    }
   ],
   "source": [
    "# combine all data into single dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    file_input = os.path.join('./data_cleaned',file)\n",
    "    df_temp = pd.read_csv(file_input)\n",
    "    df_raw = pd.concat( [df_raw, df_temp], ignore_index=True)\n",
    "    print(df_raw.shape)\n",
    "    \n",
    "\n",
    "df_raw = df_raw.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round timestamp\n",
    "\n",
    "df_raw['minute'] = pd.to_datetime(df_raw['timeframe']).dt.round('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output df as csv\n",
    "\n",
    "file_output = os.path.join('./data_analysis','df_raw.csv')\n",
    "df_raw.to_csv(file_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lucia', 'ryan', 'noe', 'ann', 'bea', 'liz', 'amy', 'ron', 'ben', 'eva', 'dan', 'kim', 'pat', 'meg', 'sue', 'zoe', 'ken', 'mia', 'andreas']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# number of students\n",
    "\n",
    "namelist = set(df_raw['weighted_name'])\n",
    "namelist = list(namelist)\n",
    "print(namelist)\n",
    "\n",
    "n = len(namelist)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis (Proximity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate euclidean distance \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def map_distance(x1,y1,x2,y2):\n",
    "    dist = np.sqrt((x1-x2)**2+(y1-y2)**2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create df_pos to determine proximity\n",
    "\n",
    "collab_dist = 1\n",
    "tool_dist = 0.2\n",
    "laser_coords = [1.50,0.75]\n",
    "printer_coords = [0.50,1.1]\n",
    "tools = ['laser_cutter', '3D_printer']\n",
    "activities = namelist + tools \n",
    "minute_index = list(set(df_raw['minute']))\n",
    "\n",
    "df_pos = df_raw.groupby(['minute','weighted_name'])['Head_x','Head_y', \n",
    "                                                    'movementAmount','isTalking',\n",
    "                                                    'headAngle','Head_z', \n",
    "                                                    'ShoulderLeft_x', 'ShoulderLeft_y', 'ShoulderLeft_z', \n",
    "                                                    'ShoulderRight_x','ShoulderRight_y', 'ShoulderRight_z', \n",
    "                                                    'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z', \n",
    "                                                    'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z',\n",
    "                                                    'HandLeft_x', 'HandLeft_y', 'HandLeft_z', \n",
    "                                                    'HandRight_x', 'HandRight_y', 'HandRight_z', \n",
    "                                                    'leanVector_x', 'leanVector_z','activity'].mean()\n",
    "\n",
    "df_pos = pd.concat([df_pos, pd.DataFrame(columns = activities)],axis=1)\n",
    "df_pos.fillna(0,inplace=True)\n",
    "\n",
    "for i in range(len(minute_index)):\n",
    "    time = minute_index[i]\n",
    "    df_temp = df_pos.xs(minute_index[i])\n",
    "    df_temp = df_temp.reset_index()\n",
    "\n",
    "# Activity : Collaboration\n",
    "    for j in range(df_temp.shape[0]-1):\n",
    "        c = df_temp.shape[0]-j-1\n",
    "        for k in range(c):\n",
    "            d = k + j + 1\n",
    "            name1 = df_temp.iloc[j][0]\n",
    "            name2 = df_temp.iloc[d][0]\n",
    "            name1_x = df_temp.iloc[j][1]\n",
    "            name1_y = df_temp.iloc[j][2]\n",
    "            name2_x = df_temp.iloc[d][1]\n",
    "            name2_y = df_temp.iloc[d][2]\n",
    "            if map_distance(name1_x,name1_y,name2_x,name2_y) <= collab_dist:\n",
    "                df_pos.loc[(time,name1),name2] = 1\n",
    "                df_pos.loc[(time,name2),name1] = 1\n",
    "\n",
    "# Activity : Tool Use\n",
    "            if map_distance(name1_x,name1_y,laser_coords[0],laser_coords[1]) <= tool_dist:\n",
    "                df_pos.loc[(time,name1),'laser_cutter'] = 1\n",
    "            if map_distance(name1_x,name1_y,printer_coords[0],printer_coords[1]) <= tool_dist:\n",
    "                df_pos.loc[(time,name1),'3D_printer'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output df_pos as csv\n",
    "\n",
    "file_output = os.path.join('./data_analysis','df_pos.csv')\n",
    "df_pos.to_csv(file_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis (Building Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3882, 50)\n"
     ]
    }
   ],
   "source": [
    "# select data for model building\n",
    "\n",
    "file = 'df_pos.csv'\n",
    "file_input = os.path.join('./data_analysis',file)\n",
    "df_analysis = pd.read_csv(file_input)\n",
    "print(df_analysis.shape)\n",
    "    \n",
    "X = df_analysis[['Head_x', 'Head_y','movementAmount','isTalking', \n",
    "                 'headAngle', 'Head_z', \n",
    "                 'ShoulderLeft_x', 'ShoulderLeft_y','ShoulderLeft_z', \n",
    "                 'ShoulderRight_x', 'ShoulderRight_y','ShoulderRight_z', \n",
    "                 'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z',\n",
    "                 'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z', \n",
    "                 'HandLeft_x','HandLeft_y', 'HandLeft_z', \n",
    "                 'HandRight_x', 'HandRight_y', 'HandRight_z',\n",
    "                 'leanVector_x', 'leanVector_z', \n",
    "                 'zoe', 'pat', 'meg', 'ken', 'ann','kim', 'noe', \n",
    "                 'mia', 'ron', 'andreas', 'eva', 'liz', 'ben', 'dan',\n",
    "                 'tonya', 'sue', 'ryan', 'lucia', 'amy', 'bea', \n",
    "                 'laser_cutter','3D_printer']].values\n",
    "\n",
    "y = df_analysis['activity'].values\n",
    "dummy_y = pd.get_dummies(df_analysis['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16231137283768862\n",
      "0.041201716738197426\n",
      "[[ 6  2  6  8  3  4  4  2  4  1  2  2  1  0  3  3  4  1  0  0  1  0]\n",
      " [ 7  5  2  6  1  2  0  4  3  2  0  1  0  0  2  4  1  2  1  0  2  1]\n",
      " [ 6  4  6  6  2  3  1  1  2  3  0  1  2  0  1  1  0  1  1  0  2  2]\n",
      " [ 4  5  8  3  5  4  1  4  1  1  1  3  0  1  1  1  1  2  1  1  2  1]\n",
      " [ 4  7  3  5  4  1  3  3  2  3  1  2  1  0  1  2  1  2  1  0  1  1]\n",
      " [ 8  5  1  5  2  2  2  3  4  2  2  2  1  0  1  2  1  1  0  1  1  1]\n",
      " [ 4  4  4 12  1  2  3  1  1  2  3  2  1  1  4  3  3  3  1  1  0  1]\n",
      " [ 4  7  4  9  4  1  5  0  2  1  0  1  3  4  1  1  0  1  0  2  3  0]\n",
      " [ 8  4  6  3  0  4  3  3  5  1  1  0  1  1  1  0  0  0  1  3  1  0]\n",
      " [11  2  9  5  4  2  5  1  1  5  1  2  1  0  1  2  3  0  0  0  0  1]\n",
      " [ 7  3  8  6  3  3  2  4  4  2  1  2  2  2  3  1  1  0  0  0  2  1]\n",
      " [ 8  8  6  5  2  3  1  5  1  6  1  1  2  1  1  1  2  0  1  0  1  0]\n",
      " [ 7  8  9  3  1  2  3  4  5  1  2  3  0  3  3  5  1  2  0  0  0  2]\n",
      " [ 3  7  7  5  6  7  4  6  2  2  3  0  1  1  1  1  2  3  3  0  0  0]\n",
      " [ 7  6  4  6  7  0  1  2  5  0  0  1  1  1  1  3  1  2  0  0  3  0]\n",
      " [ 5  3  5  5  1  4  3  1  2  0  2  1  2  3  2  1  3  3  1  0  3  2]\n",
      " [ 6  4  9  5  3  4  1  2  0  2  2  4  2  0  5  1  1  1  2  1  0  1]\n",
      " [ 8  4  4  5  0  1  3  2  3  3  0  0  3  1  2  4  3  1  2  0  1  0]\n",
      " [ 6  4 10  6  1  1  3  1  2  0  1  3  0  1  2  6  5  0  1  0  4  1]\n",
      " [ 8  4  6  3  0  4  2  5  5  2  1  0  2  0  2  2  2  3  1  0  3  1]\n",
      " [ 7  6  2  2  3  3  1  1  1  1  1  1  1  4  2  0  5  3  1  2  0  1]\n",
      " [ 6  6  5  4  4  1  4  1  1  2  4  1  0  1  2  2  0  0  1  1  0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        camy       0.04      0.11      0.06        57\n",
      "    candreas       0.05      0.11      0.06        46\n",
      "        cann       0.05      0.13      0.07        45\n",
      "        cbea       0.03      0.06      0.04        51\n",
      "        cben       0.07      0.08      0.08        48\n",
      "        cdan       0.03      0.04      0.04        47\n",
      "        ceva       0.05      0.05      0.05        57\n",
      "        cken       0.00      0.00      0.00        53\n",
      "        ckim       0.09      0.11      0.10        46\n",
      "        cliz       0.12      0.09      0.10        56\n",
      "      clucia       0.03      0.02      0.02        57\n",
      "        cmeg       0.03      0.02      0.02        56\n",
      "        cmia       0.00      0.00      0.00        64\n",
      "        cnoe       0.04      0.02      0.02        64\n",
      "        cron       0.02      0.02      0.02        51\n",
      "       cryan       0.02      0.02      0.02        52\n",
      "        csue       0.03      0.02      0.02        56\n",
      "      ctonya       0.03      0.02      0.02        50\n",
      "        czoe       0.05      0.02      0.03        58\n",
      "      tlaser       0.00      0.00      0.00        56\n",
      "    tprinter       0.00      0.00      0.00        48\n",
      "        zpat       0.06      0.02      0.03        47\n",
      "\n",
      "   micro avg       0.04      0.04      0.04      1165\n",
      "   macro avg       0.04      0.04      0.04      1165\n",
      "weighted avg       0.04      0.04      0.04      1165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Supervised: KNeighborsClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(knn.score(X_train, y_train))\n",
    "print(knn.score(X_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "1941/1941 [==============================] - 2s 1ms/step - loss: 3.1393 - acc: 0.0407\n",
      "1941/1941 [==============================] - 1s 281us/step\n",
      "Epoch 1/1\n",
      "1941/1941 [==============================] - 2s 1ms/step - loss: 3.3022 - acc: 0.0438\n",
      "1941/1941 [==============================] - 1s 296us/step\n",
      "Baseline: 3.81% (0.36%)\n"
     ]
    }
   ],
   "source": [
    "# Supervised: Deep Learning\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size = 0.3, random_state=42)\n",
    "\n",
    "\n",
    "n_cols = X_train.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "\n",
    "def baseline_model():\n",
    "    dl = Sequential()\n",
    "    dl.add(Dense(10, activation='relu', input_shape = input_shape))\n",
    "    dl.add(Dense(10, activation='relu'))\n",
    "    dl.add(Dense(dummy_y.shape[1], activation='softmax'))\n",
    "    dl.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "    return dl\n",
    "\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=1, batch_size=1)\n",
    "\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=2)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
