{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**: describe your dataset, and why you're interested in it\n",
    "\n",
    "In this dataset, Kinect sensors captured students' body postures, location, and gestures in a makerspace over the period of a 13-weeks semester, recording nearly half a million observations from 16 students enrolled in a class. \n",
    "\n",
    "I am interested in this dataset because I am currently involved in the next iteration of the Makerspace project and it would be good to gain more familiarity with the dataset by analyzing it in this final project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research question(s)**: describe the overall research question of your project\n",
    "\n",
    "Can the activities of students (e.g., using a laser cutter, interacting with someone, etc.) be detected from their location and their body postures in the makerspace?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypotheses**:\n",
    "    * Describe 2-3 hypotheses that you're planning to test with your dataset\n",
    "    * Each hypoteses should be based on academic research (cite a paper) and/or background knowledge that you have about the dataset if you've collected it yourself (e.g., if you've conducted interviews)\n",
    "    * Each hypotheses should be formulated as an affirmation (and not a question)\n",
    "    * You can also describe alternative hypotheses, if you think that your results could go either way (but again, have a rationale as for why)\n",
    "\n",
    "    \n",
    "**Hypothesis 1**\n",
    "Using the x-y coordinates of the head joint, the approximate position of students can be inferred, which then informs if they are using tools or working with others within the makerspace. \n",
    "\n",
    "**Hypothesis 2**\n",
    "Students who have joint line of sight with their partners indicates collaboration within the makerspace. \n",
    "\n",
    "**Papers**\n",
    "Hall, E. T. (1966). The Hidden Dimension. Anchor Books.\n",
    "\n",
    "Reilly, J.M. et al. Exploring Collaboration Using Motion Sensors and Multi-Modal Learning Analytics. Educational Data Mining Conference 2018.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**:\n",
    "    * how are you planning to test each hypothesis? What models are you thinking of using?\n",
    "I am planning to first derive features such as proximity, hand gesturing and line of sight of students to indicate the activities of students within the makerspace. Thereafter, I will train a machine learning algorithm based on these features to predict the activities of students. As a test of the accuracy of the algorithm, I will exclude one week of data during the training stage and test the algorithm later using this test set. For the test set, manual coding using video would be done to denote the activities of the students instead of using the generated features. \n",
    "\n",
    "\n",
    "    * what are the best results you can hope for? Is that interesting / relevant for other researchers?\n",
    "The best results would be a strong correlation between the generated features and student activities. This would be interesting for other researchers as the profiling of student activities could lead to other areas of research such as personalized interventions and quality of social interactions.\n",
    "\n",
    "    * what are implications of your potential findings for practioners? \n",
    "Students activities could be inferred from the generated features without the teachers having to pay continuous attention to each and every student within the makerspace. This presents practioners a way of understanding their students to cater to their individual learning needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Threads**\n",
    "    * Describe issues that might arise during the analyses above\n",
    "It might be possible that we may not derive features that can successfully predict the activities of students or we may also be looking at the incorrect features of the body movement to inform us of the activities of students.\n",
    "\n",
    "    * Come up with backup plans in case you run into theses issues\n",
    "Think of alternative features of the students' body movement or allow the models to uncover the relevant features without making any prior assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe your raw data below; provide definition / explanations for the measures you're using\n",
    "\n",
    "The raw data consists of student information (eg person_id, name), skeletal joint data, facial expressions (eg isTalking) and collection information (eg timestamp, kinect_id). For the purpose of this investigation, we will drop information mostly related to facial expressions as 1) these variables are dichotomous 2) they contain a limited range of facial expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean you data in this section, and make sure it's ready to be analyzed for next week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv']\n"
     ]
    }
   ],
   "source": [
    "# import files from directory\n",
    "\n",
    "import os\n",
    "\n",
    "files = []\n",
    "\n",
    "for file in os.listdir('./test'):\n",
    "    if file.endswith('.csv'):\n",
    "        files.append(file)\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'test',\n",
       " 'dataset',\n",
       " 'data_cleaned',\n",
       " 'code',\n",
       " 'Wee9-Final-Project.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " '.git']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new folder to store cleaned data\n",
    "\n",
    "os.mkdir('./data_cleaned')\n",
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv']\n"
     ]
    }
   ],
   "source": [
    "# clean data and output as csv to folder\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "instructor_list = ['sammie','othertwo','otherthree','name','yanni','carlie','billy',\n",
    "                   'othereight','otherfive','otherfour','otherone','otherseven','othersix']\n",
    "\n",
    "# Select rows for timestamp 4/6/2018  4:10:37 PM to 4/6/2018  5:50:30 PM \n",
    "v =[]\n",
    "for i in range(25533,29507): \n",
    "    v.append(i) \n",
    "    \n",
    "for file in os.listdir('./test'):\n",
    "    if file.endswith('.csv'):\n",
    "        file_input = os.path.join('./test',file)\n",
    "        df = pd.read_csv(file_input)\n",
    "        df = df.loc[df['Unnamed: 0'].isin(v)]\n",
    "        df_cleaned = df.drop([df.columns[0],'name_aga_conf','confidence_value','name_aga_freq','frequency','freq_count',\n",
    "                            'isWearingGlasses','isSmiling','leftHandRaised','rightHandRaised',\n",
    "                           'ip','et_timestamp','skeleton','person_id_lifespan','face_detected','timestamp'], axis=1)\n",
    "        df_cleaned.dropna(inplace=True)\n",
    "        \n",
    "        for name in instructor_list:\n",
    "            indexNames = df_cleaned[df_cleaned['weighted_name'] == name].index\n",
    "            df_cleaned.drop(indexNames,inplace=True)\n",
    "        \n",
    "        df_cleaned.reset_index(inplace=True,drop=True)\n",
    "        file_output = os.path.join('./data_cleaned',file)\n",
    "        df_cleaned.to_csv(file_output)\n",
    "        \n",
    "print(os.listdir('./data_cleaned'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis (Preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv']\n"
     ]
    }
   ],
   "source": [
    "# import files from directory\n",
    "\n",
    "import os\n",
    "\n",
    "files = []\n",
    "\n",
    "for file in os.listdir('./data_cleaned'):\n",
    "    if file.endswith('.csv'):\n",
    "        files.append(file)\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_analysis',\n",
       " '.DS_Store',\n",
       " 'test',\n",
       " 'dataset',\n",
       " 'data_cleaned',\n",
       " 'code',\n",
       " 'Wee9-Final-Project.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " '.git']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new folder to store data for analysis\n",
    "\n",
    "os.mkdir('./data_analysis')\n",
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2181, 31)\n"
     ]
    }
   ],
   "source": [
    "# combine all data into single dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    file_input = os.path.join('./data_cleaned',file)\n",
    "    df_temp = pd.read_csv(file_input)\n",
    "    df_raw = pd.concat( [df_raw, df_temp], ignore_index=True)\n",
    "    print(df_raw.shape)\n",
    "    \n",
    "\n",
    "df_raw = df_raw.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round timestamp\n",
    "\n",
    "df_raw['minute'] = pd.to_datetime(df_raw['timeframe']).dt.round('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pat', 'dan', 'eva', 'mia', 'ben', 'ken', 'zoe', 'sue', 'kim']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# number of students\n",
    "\n",
    "master_namelist = ['ann', 'ryan', 'ken', 'pat', 'liz', 'zoe', 'kim', 'eva', \n",
    "                   'ron', 'meg', 'dan', 'sue', 'ben', 'andreas', 'mia', \n",
    "                   'bea', 'amy', 'lucia', 'noe', 'tonya']\n",
    "\n",
    "namelist = set(df_raw['weighted_name'])\n",
    "namelist = list(namelist)\n",
    "print(namelist)\n",
    "\n",
    "n = len(namelist)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output df as csv\n",
    "\n",
    "file_output = os.path.join('./data_analysis','df_raw.csv')\n",
    "df_raw.to_csv(file_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis (Proximity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['df_raw.csv']\n"
     ]
    }
   ],
   "source": [
    "# import files from directory\n",
    "\n",
    "import os\n",
    "\n",
    "files_a = []\n",
    "\n",
    "for file in os.listdir('./data_analysis'):\n",
    "    if file.endswith('.csv'):\n",
    "        files_a.append(file)\n",
    "\n",
    "print(files_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2181, 31)\n"
     ]
    }
   ],
   "source": [
    "# combine all data into single dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.DataFrame()\n",
    "\n",
    "for file in files_a:\n",
    "    file_input = os.path.join('./data_analysis',file)\n",
    "    df_temp = pd.read_csv(file_input)\n",
    "    df_raw = pd.concat( [df_raw, df_temp], ignore_index=True)\n",
    "    df_raw = df_raw.drop('Unnamed: 0', axis=1)\n",
    "    print(df_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate euclidean distance \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def map_distance(x1,y1,x2,y2):\n",
    "    dist = np.sqrt((x1-x2)**2+(y1-y2)**2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create df_pos_function to generate proximity feature\n",
    "\n",
    "def df_pos_function(df_raw,dist,namelist):\n",
    "    laser_coords = [1.50,0.75]\n",
    "    printer_coords = [3.75,0.75]\n",
    "    tools = ['laser_cutter', '3D_printer']\n",
    "    activities = namelist + tools \n",
    "    minute_index = list(set(df_raw['minute']))\n",
    "\n",
    "    df_pos = df_raw.groupby(['minute','weighted_name'])['Head_x','Head_y', \n",
    "                                                        'movementAmount','isTalking',\n",
    "                                                        'headAngle','Head_z', \n",
    "                                                        'ShoulderLeft_x', 'ShoulderLeft_y', 'ShoulderLeft_z', \n",
    "                                                        'ShoulderRight_x','ShoulderRight_y', 'ShoulderRight_z', \n",
    "                                                        'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z', \n",
    "                                                        'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z',\n",
    "                                                        'HandLeft_x', 'HandLeft_y', 'HandLeft_z', \n",
    "                                                        'HandRight_x', 'HandRight_y', 'HandRight_z', \n",
    "                                                        'leanVector_x', 'leanVector_z'].mean()\n",
    "\n",
    "    df_pos = pd.concat([df_pos, pd.DataFrame(columns = activities)],axis=1)\n",
    "    df_pos.fillna(0,inplace=True)\n",
    "\n",
    "    for i in range(len(minute_index)):\n",
    "        time = minute_index[i]\n",
    "        df_temp = df_pos.xs(minute_index[i])\n",
    "        df_temp = df_temp.reset_index()\n",
    "\n",
    "    # Activity\n",
    "        for j in range(df_temp.shape[0]-1):\n",
    "            c = df_temp.shape[0]-j-1\n",
    "            for k in range(c):\n",
    "                d = k + j + 1\n",
    "                name1 = df_temp.iloc[j][0]\n",
    "                name2 = df_temp.iloc[d][0]\n",
    "                name1_x = df_temp.iloc[j][1]\n",
    "                name1_y = df_temp.iloc[j][2]\n",
    "                name2_x = df_temp.iloc[d][1]\n",
    "                name2_y = df_temp.iloc[d][2]\n",
    "\n",
    "                # Collaboration\n",
    "                if map_distance(name1_x,name1_y,name2_x,name2_y) <= dist:\n",
    "                    df_pos.loc[(time,name1),name2] = 1\n",
    "                    df_pos.loc[(time,name2),name1] = 1\n",
    "\n",
    "                # Tool Use\n",
    "                if map_distance(name1_x,name1_y,laser_coords[0],laser_coords[1]) <= dist:\n",
    "                    df_pos.loc[(time,name1),'laser_cutter'] = 1\n",
    "                if map_distance(name1_x,name1_y,printer_coords[0],printer_coords[1]) <= dist:\n",
    "                    df_pos.loc[(time,name1),'3D_printer'] = 1\n",
    "    return df_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output df_pos as csv\n",
    "\n",
    "dist = 1.5\n",
    "df_pos = df_pos_function(df_raw,dist,master_namelist)\n",
    "file_output = os.path.join('./data_analysis','df_pos.csv')\n",
    "df_pos.to_csv(file_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis (Building Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195, 51)\n"
     ]
    }
   ],
   "source": [
    "# select data for model building\n",
    "\n",
    "file = '1.5_df_pos(code).csv'\n",
    "file_input = os.path.join('./code',file)\n",
    "df_analysis = pd.read_csv(file_input)\n",
    "print(df_analysis.shape)\n",
    "\n",
    "selected = ['Head_x', 'Head_y','movementAmount','isTalking', 'headAngle', 'Head_z', \n",
    "            'ShoulderLeft_x', 'ShoulderLeft_y','ShoulderLeft_z', \n",
    "            'ShoulderRight_x', 'ShoulderRight_y','ShoulderRight_z', \n",
    "            'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z',\n",
    "            'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z', \n",
    "            'HandLeft_x','HandLeft_y', 'HandLeft_z', \n",
    "            'HandRight_x', 'HandRight_y', 'HandRight_z',\n",
    "            'leanVector_x', 'leanVector_z', \n",
    "            'laser_cutter','3D_printer'] + master_namelist\n",
    "\n",
    "X = df_analysis[selected].values\n",
    "\n",
    "y = df_analysis['activity'].values\n",
    "dummy_y = pd.get_dummies(df_analysis['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6911764705882353\n",
      "0.7288135593220338\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0]\n",
      " [ 0  0  0  0  2  0]\n",
      " [ 2  0  0  0  4  0]\n",
      " [ 2  0  0  0 42  1]\n",
      " [ 0  0  0  0  3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cben       0.00      0.00      0.00         0\n",
      "        ckim       0.00      0.00      0.00         2\n",
      "        cmia       0.00      0.00      0.00         2\n",
      "        czoe       0.00      0.00      0.00         6\n",
      "           i       0.79      0.93      0.86        45\n",
      "    tprinter       0.50      0.25      0.33         4\n",
      "\n",
      "   micro avg       0.73      0.73      0.73        59\n",
      "   macro avg       0.22      0.20      0.20        59\n",
      "weighted avg       0.64      0.73      0.68        59\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Supervised Learning: KNeighborsClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(knn.score(X_train, y_train))\n",
    "print(knn.score(X_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6.csv', '7.csv', '5.csv', '4.csv', '3.csv', '2.csv', '10.csv', '11.csv', '13.csv', '12.csv', '9.csv']\n"
     ]
    }
   ],
   "source": [
    "# import files from directory\n",
    "\n",
    "import os\n",
    "\n",
    "files = []\n",
    "\n",
    "for file in os.listdir('./dataset'):\n",
    "    if file.endswith('.csv'):\n",
    "        files.append(file)\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_analysis',\n",
       " '.DS_Store',\n",
       " 'test',\n",
       " 'dataset',\n",
       " 'data_cleaned',\n",
       " 'code',\n",
       " 'data_prediction',\n",
       " 'Wee9-Final-Project.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " '.git']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new folder to store predicted data\n",
    "\n",
    "os.mkdir('./data_prediction')\n",
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98056, 30)\n",
      "(129868, 30)\n",
      "(145990, 30)\n",
      "(176603, 30)\n",
      "(190476, 30)\n",
      "(235451, 30)\n",
      "(295929, 30)\n",
      "(345678, 30)\n",
      "(388545, 30)\n",
      "(411932, 30)\n",
      "(422557, 30)\n"
     ]
    }
   ],
   "source": [
    "# clean data and combine into single dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "instructor_list = ['sammie','othertwo','otherthree','name','yanni','carlie','billy',\n",
    "                   'othereight','otherfive','otherfour','otherone','otherseven','othersix']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    file_input = os.path.join('./dataset',file)\n",
    "    df_temp = pd.read_csv(file_input)\n",
    "    df_cleaned = df_temp.drop([df_temp.columns[0],'name_aga_conf','confidence_value','name_aga_freq','frequency','freq_count',\n",
    "                            'isWearingGlasses','isSmiling','leftHandRaised','rightHandRaised',\n",
    "                           'ip','et_timestamp','skeleton','person_id_lifespan','face_detected','timestamp'], axis=1)\n",
    "    \n",
    "    df_cleaned.dropna(inplace=True)\n",
    "        \n",
    "    for name in instructor_list:\n",
    "        indexNames = df_cleaned[df_cleaned['weighted_name'] == name].index\n",
    "        df_cleaned.drop(indexNames,inplace=True)\n",
    "        \n",
    "    df_cleaned.reset_index(inplace=True,drop=True)\n",
    "    df = pd.concat( [df, df_cleaned], ignore_index=True)\n",
    "    print(df.shape)\n",
    "\n",
    "# round timestamp\n",
    "df['minute'] = pd.to_datetime(df['timeframe']).dt.round('min')\n",
    "\n",
    "file_output = os.path.join('./data_prediction','df0.csv')\n",
    "df.to_csv(file_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate proximity feature\n",
    "\n",
    "dist = 1.5\n",
    "df_pos = df_pos_function(df,dist,master_namelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "\n",
    "selected = ['Head_x', 'Head_y','movementAmount','isTalking', 'headAngle', 'Head_z', \n",
    "            'ShoulderLeft_x', 'ShoulderLeft_y','ShoulderLeft_z', \n",
    "            'ShoulderRight_x', 'ShoulderRight_y','ShoulderRight_z', \n",
    "            'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z',\n",
    "            'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z', \n",
    "            'HandLeft_x','HandLeft_y', 'HandLeft_z', \n",
    "            'HandRight_x', 'HandRight_y', 'HandRight_z',\n",
    "            'leanVector_x', 'leanVector_z', \n",
    "            'laser_cutter','3D_printer'] + master_namelist\n",
    "\n",
    "X = df_pos[selected].values\n",
    "\n",
    "y_pred = knn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output predicted data\n",
    "\n",
    "df_pos['activity'] = y_pred\n",
    "file_output = os.path.join('./data_prediction','df_predicted.csv')\n",
    "df_pos.to_csv(file_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataframe for visualization\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file = 'df_predicted.csv'\n",
    "file_input = os.path.join('./data_prediction',file)\n",
    "df_pred = pd.read_csv(file_input)\n",
    "\n",
    "df_graph = pd.DataFrame()\n",
    "df_graph['minute'] = pd.to_datetime(df_pred['minute'])\n",
    "df_graph['date'] = df_graph['minute'].dt.date\n",
    "df_graph['time'] = 1\n",
    "df_graph['weighted_name'] = df_pred['weighted_name']\n",
    "df_graph['activity'] = df_pred['activity']\n",
    "\n",
    "df_plot = df_graph.groupby(['weighted_name','date','activity'])['time'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data for plotting\n",
    "\n",
    "file_output = os.path.join('./data_prediction','df_plot.csv')\n",
    "df_plot.to_csv(file_output)\n",
    "\n",
    "# file = 'df_plot.csv'\n",
    "# file_input = os.path.join('./data_prediction',file)\n",
    "# df_plot = pd.read_csv(file_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create bokeh plot\n",
    "\n",
    "from bokeh.plotting import ColumnDataSource, figure,show\n",
    "from bokeh.io import output_notebook, curdoc, output_file\n",
    "from bokeh.models import HoverTool, Select, Slider\n",
    "from bokeh.models.widgets import DateRangeSlider\n",
    "from bokeh.layouts import widgetbox, row, column, layout\n",
    "\n",
    "source = ColumnDataSource(data={\n",
    "    'x'       : data.loc[1970].fertility,\n",
    "    'y'       : data.loc[1970].life\n",
    "})\n",
    "\n",
    "list_of_activity = list(set(df_plot['activity']))\n",
    "\n",
    "\n",
    "p = figure(x_range=list_of_activity, title=\"Student Activity\")\n",
    "\n",
    "p.vbar(x=list_of_activity, top=df_plot['time'], width=0.9)\n",
    "\n",
    "date_range_slider = DateRangeSlider(title=\"Date Range\", start=df_graph['date'].min(), \n",
    "                                    end=df_graph['date'].max(), step=1)\n",
    "\n",
    "select_name = Select(options=[list(set(df_graph['weighted_name']))],value='ann', title='Student Name')\n",
    "\n",
    "def update_slider(attr, old, new):\n",
    "    N = date_range_slider.value\n",
    "    new_data = {\n",
    "        'x'       : df_plot.loc[N].activity,\n",
    "        'y'       : df_plot.loc[N].time,\n",
    "    }\n",
    "    source.data = new_data\n",
    "\n",
    "date_range_slider.on_change('value', update_slider)\n",
    "\n",
    "def update_selection(attr, old, new):\n",
    "    N = date_range_slider.value\n",
    "    new_data = {\n",
    "        'x'       : data.loc[yr][x],\n",
    "        'y'       : data.loc[yr][y],\n",
    "    }\n",
    "    source.data = new_data\n",
    "\n",
    "select_name.on_change('value', update_selection)\n",
    "\n",
    "layout = row(widgetbox(slider, select_name), p)\n",
    "curdoc().add_root(layout)\n",
    "\n",
    "output_file('plot.html')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
