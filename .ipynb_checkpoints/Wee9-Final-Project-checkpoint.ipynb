{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**: describe your dataset, and why you're interested in it\n",
    "\n",
    "In this dataset, Kinect sensors captured students' body postures, location, and gestures in a makerspace over the period of a 13-weeks semester, recording nearly half a million observations from 16 students enrolled in a class. \n",
    "\n",
    "I am interested in this dataset because I am currently involved in the next iteration of the Makerspace project and it would be good to gain more familiarity with the dataset by analyzing it in this final project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research question(s)**: describe the overall research question of your project\n",
    "\n",
    "Can we generate “profiles” (or personas) for students, based on their behavior in the space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypotheses**:\n",
    "    * Describe 2-3 hypotheses that you're planning to test with your dataset\n",
    "    * Each hypoteses should be based on academic research (cite a paper) and/or background knowledge that you have about the dataset if you've collected it yourself (e.g., if you've conducted interviews)\n",
    "    * Each hypotheses should be formulated as an affirmation (and not a question)\n",
    "    * You can also describe alternative hypotheses, if you think that your results could go either way (but again, have a rationale as for why)\n",
    "\n",
    "    \n",
    "**Hypothesis 1**\n",
    "Higher velocity movements are correlated with personality traits such as extraversion and openness. \n",
    "\n",
    "**Hypothesis 2**\n",
    "Students who lean towards their partners when collaborating within the makerspace correlates more with the personality trait of agreebleness, while students who lean away correlates more with neuroticism. \n",
    "\n",
    "\n",
    "**Papers**\n",
    "Wache, J. (2014) The secret language of our body - Affect and personality recognition using physiological signals. In Proceedings of the 16th International Conference on Multimodal Interaction (pp. 389-393). ICMI \n",
    "\n",
    "McCrae, R.R. & John, O.P. (1992) An introduction to the five- factor model and its applications. Journal of personality 60(2), 175–215.\n",
    "\n",
    "Srivastava, R., Feng, J., Roy, S., Sim, T., and Yan, S. Don’t Ask Me What I’m Like, Just Watch and Listen. Proceedings of the 20th ACM international conference on Multimedia. ACM, 2012., (2012), 329–338.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**:\n",
    "    * how are you planning to test each hypothesis? What models are you thinking of using?\n",
    "I am planning to use clustering methods to group students based on the characteristics of the body movement (eg low or high velocity, lean towards or lean away) and use deep learning models to predict their personality traits.\n",
    "\n",
    "    * what are the best results you can hope for? Is that interesting / relevant for other researchers?\n",
    "The best results would be a strong correlation between the students' body language and personality traits. This would be interesting for other researchers as personality profiling could lead to other areas of research such as personalized interventions and quality of social interactions.\n",
    "\n",
    "    * what are implications of your potential findings for practioners? \n",
    "Personality traits could be inferred from body language data without the traditional use of surveys. This presents practioners a way of understanding their students to cater to their individual learning needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Threads**\n",
    "    * Describe issues that might arise during the analyses above\n",
    "It might be possible that we may not derive clear clusters that separate the students or we may also be looking at the incorrect characteristics of the body movement to inform us of the personality traits.\n",
    "\n",
    "    * Come up with backup plans in case you run into theses issues\n",
    "Think of alternative characteristics of the students' body movement or allow the models to uncover the relevant characteristics without making any prior assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe your raw data below; provide definition / explanations for the measures you're using\n",
    "\n",
    "The raw data consists of student information (eg person_id, name), skeletal joint data, facial expressions (eg isSmiling) and collection information (eg timestamp, kinect_id). For the purpose of this investigation, we will drop information related to facial expressions as 1) these variables are dichotomous 2) they contain a limited range of facial expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean you data in this section, and make sure it's ready to be analyzed for next week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6.csv', '7.csv', '5.csv', '4.csv', '3.csv', '2.csv', '10.csv', '11.csv', '13.csv', '12.csv', '9.csv']\n"
     ]
    }
   ],
   "source": [
    "# import files from directory\n",
    "\n",
    "import os\n",
    "\n",
    "files = []\n",
    "\n",
    "for file in os.listdir('./dataset'):\n",
    "    if file.endswith('.csv'):\n",
    "        files.append(file)\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'dataset',\n",
       " 'data_cleaned',\n",
       " 'Wee9-Final-Project.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " '.git']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new folder to store cleaned data\n",
    "\n",
    "os.mkdir('./data_cleaned')\n",
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6.csv', '7.csv', '5.csv', '4.csv', '3.csv', '2.csv', '10.csv', '11.csv', '13.csv', '12.csv', '9.csv']\n"
     ]
    }
   ],
   "source": [
    "# clean data and output as csv to folder\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "for file in os.listdir('./dataset'):\n",
    "    if file.endswith('.csv'):\n",
    "        file_input = os.path.join('./dataset',file)\n",
    "        df = pd.read_csv(file_input,parse_dates=True,index_col='timestamp')\n",
    "        cleaned = df.drop([df.columns[0],'name_aga_conf','confidence_value','name_aga_freq','frequency','freq_count',\n",
    "                           'isTalking','isWearingGlasses','isSmiling','leftHandRaised','rightHandRaised',\n",
    "                           'ip','et_timestamp','skeleton','face_detected'], axis=1)\n",
    "        cleaned.dropna(inplace=True)\n",
    "        file_output = os.path.join('./data_cleaned',file)\n",
    "        cleaned.to_csv(file_output)\n",
    "        \n",
    "print(os.listdir('./data_cleaned'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6.csv', '7.csv', '5.csv', '4.csv', '3.csv', '2.csv', '10.csv', '11.csv', '13.csv', '12.csv', '9.csv']\n"
     ]
    }
   ],
   "source": [
    "# import files from directory\n",
    "\n",
    "import os\n",
    "\n",
    "files = []\n",
    "\n",
    "for file in os.listdir('./data_cleaned'):\n",
    "    if file.endswith('.csv'):\n",
    "        files.append(file)\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133242, 30)\n",
      "(203950, 30)\n",
      "(248749, 30)\n",
      "(295838, 30)\n",
      "(331968, 30)\n",
      "(415609, 30)\n",
      "(508608, 30)\n",
      "(605386, 30)\n",
      "(692745, 30)\n",
      "(759264, 30)\n",
      "(780442, 30)\n"
     ]
    }
   ],
   "source": [
    "# combine all data into single dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    file_input = os.path.join('./data_cleaned',file)\n",
    "    df_temp = pd.read_csv(file_input,parse_dates=True,index_col='timestamp')\n",
    "    df = pd.concat( [df, df_temp], ignore_index=True)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kinect_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>movementAmount</th>\n",
       "      <th>headAngle</th>\n",
       "      <th>Head_x</th>\n",
       "      <th>Head_y</th>\n",
       "      <th>Head_z</th>\n",
       "      <th>ShoulderLeft_x</th>\n",
       "      <th>ShoulderLeft_y</th>\n",
       "      <th>ShoulderLeft_z</th>\n",
       "      <th>...</th>\n",
       "      <th>H1</th>\n",
       "      <th>H2</th>\n",
       "      <th>ShoulderMid_x</th>\n",
       "      <th>ShoulderMid_y</th>\n",
       "      <th>ShoulderMid_z</th>\n",
       "      <th>V1</th>\n",
       "      <th>ElbowMid_x</th>\n",
       "      <th>ElbowMid_y</th>\n",
       "      <th>ElbowMid_z</th>\n",
       "      <th>V2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.615765e+09</td>\n",
       "      <td>72057594038539369</td>\n",
       "      <td>13.153</td>\n",
       "      <td>1.101641</td>\n",
       "      <td>1.157095</td>\n",
       "      <td>3.320800</td>\n",
       "      <td>1.096605</td>\n",
       "      <td>1.181513</td>\n",
       "      <td>3.387554</td>\n",
       "      <td>1.009208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231078</td>\n",
       "      <td>0.249384</td>\n",
       "      <td>1.121523</td>\n",
       "      <td>3.378288</td>\n",
       "      <td>0.910899</td>\n",
       "      <td>0.197628</td>\n",
       "      <td>1.170847</td>\n",
       "      <td>3.344927</td>\n",
       "      <td>1.056543</td>\n",
       "      <td>0.157347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.615765e+09</td>\n",
       "      <td>72057594038539369</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.101641</td>\n",
       "      <td>1.155413</td>\n",
       "      <td>3.322507</td>\n",
       "      <td>1.096537</td>\n",
       "      <td>1.180122</td>\n",
       "      <td>3.387663</td>\n",
       "      <td>1.004032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224662</td>\n",
       "      <td>0.235693</td>\n",
       "      <td>1.121065</td>\n",
       "      <td>3.379618</td>\n",
       "      <td>0.908818</td>\n",
       "      <td>0.199198</td>\n",
       "      <td>1.170402</td>\n",
       "      <td>3.348209</td>\n",
       "      <td>1.057580</td>\n",
       "      <td>0.159846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.615765e+09</td>\n",
       "      <td>72057594038539369</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.101641</td>\n",
       "      <td>1.157352</td>\n",
       "      <td>3.321452</td>\n",
       "      <td>1.096150</td>\n",
       "      <td>1.162785</td>\n",
       "      <td>3.339473</td>\n",
       "      <td>0.931730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191018</td>\n",
       "      <td>0.149868</td>\n",
       "      <td>1.111688</td>\n",
       "      <td>3.352963</td>\n",
       "      <td>0.852174</td>\n",
       "      <td>0.250205</td>\n",
       "      <td>1.122059</td>\n",
       "      <td>3.300787</td>\n",
       "      <td>0.876574</td>\n",
       "      <td>0.058525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.615765e+09</td>\n",
       "      <td>72057594038539369</td>\n",
       "      <td>11.852</td>\n",
       "      <td>1.101641</td>\n",
       "      <td>1.158329</td>\n",
       "      <td>3.323097</td>\n",
       "      <td>1.098499</td>\n",
       "      <td>1.170980</td>\n",
       "      <td>3.351069</td>\n",
       "      <td>0.966265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197910</td>\n",
       "      <td>0.075865</td>\n",
       "      <td>1.118411</td>\n",
       "      <td>3.358849</td>\n",
       "      <td>0.882791</td>\n",
       "      <td>0.222265</td>\n",
       "      <td>1.129098</td>\n",
       "      <td>3.304462</td>\n",
       "      <td>0.873087</td>\n",
       "      <td>0.056271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.615765e+09</td>\n",
       "      <td>72057594038539369</td>\n",
       "      <td>4.070</td>\n",
       "      <td>1.101641</td>\n",
       "      <td>1.157029</td>\n",
       "      <td>3.321284</td>\n",
       "      <td>1.094744</td>\n",
       "      <td>1.166033</td>\n",
       "      <td>3.350567</td>\n",
       "      <td>0.964835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194065</td>\n",
       "      <td>0.078277</td>\n",
       "      <td>1.113369</td>\n",
       "      <td>3.358484</td>\n",
       "      <td>0.883724</td>\n",
       "      <td>0.218677</td>\n",
       "      <td>1.126031</td>\n",
       "      <td>3.302213</td>\n",
       "      <td>0.871812</td>\n",
       "      <td>0.058895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      kinect_id          person_id  movementAmount  headAngle    Head_x  \\\n",
       "0  9.615765e+09  72057594038539369          13.153   1.101641  1.157095   \n",
       "1  9.615765e+09  72057594038539369           0.986   1.101641  1.155413   \n",
       "2  9.615765e+09  72057594038539369           1.678   1.101641  1.157352   \n",
       "3  9.615765e+09  72057594038539369          11.852   1.101641  1.158329   \n",
       "4  9.615765e+09  72057594038539369           4.070   1.101641  1.157029   \n",
       "\n",
       "     Head_y    Head_z  ShoulderLeft_x  ShoulderLeft_y  ShoulderLeft_z  \\\n",
       "0  3.320800  1.096605        1.181513        3.387554        1.009208   \n",
       "1  3.322507  1.096537        1.180122        3.387663        1.004032   \n",
       "2  3.321452  1.096150        1.162785        3.339473        0.931730   \n",
       "3  3.323097  1.098499        1.170980        3.351069        0.966265   \n",
       "4  3.321284  1.094744        1.166033        3.350567        0.964835   \n",
       "\n",
       "     ...           H1        H2  ShoulderMid_x  ShoulderMid_y  ShoulderMid_z  \\\n",
       "0    ...     0.231078  0.249384       1.121523       3.378288       0.910899   \n",
       "1    ...     0.224662  0.235693       1.121065       3.379618       0.908818   \n",
       "2    ...     0.191018  0.149868       1.111688       3.352963       0.852174   \n",
       "3    ...     0.197910  0.075865       1.118411       3.358849       0.882791   \n",
       "4    ...     0.194065  0.078277       1.113369       3.358484       0.883724   \n",
       "\n",
       "         V1  ElbowMid_x  ElbowMid_y  ElbowMid_z        V2  \n",
       "0  0.197628    1.170847    3.344927    1.056543  0.157347  \n",
       "1  0.199198    1.170402    3.348209    1.057580  0.159846  \n",
       "2  0.250205    1.122059    3.300787    0.876574  0.058525  \n",
       "3  0.222265    1.129098    3.304462    0.873087  0.056271  \n",
       "4  0.218677    1.126031    3.302213    0.871812  0.058895  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create columns for H1,H2,V1,V2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df['H1'] = np.sqrt((df['ShoulderLeft_x']-df['ShoulderRight_x'])**2\n",
    "                   +(df['ShoulderLeft_y']-df['ShoulderRight_y'])**2\n",
    "                   +(df['ShoulderLeft_z']-df['ShoulderRight_z'])**2)\n",
    "\n",
    "df['H2'] = np.sqrt((df['ElbowLeft_x']-df['ElbowRight_x'])**2\n",
    "                   +(df['ElbowLeft_y']-df['ElbowRight_y'])**2\n",
    "                   +(df['ElbowLeft_z']-df['ElbowRight_z'])**2)\n",
    "\n",
    "df['ShoulderMid_x'] = (df['ShoulderLeft_x']+df['ShoulderRight_x'])/2\n",
    "df['ShoulderMid_y'] = (df['ShoulderLeft_y']+df['ShoulderRight_y'])/2\n",
    "df['ShoulderMid_z'] = (df['ShoulderLeft_z']+df['ShoulderRight_z'])/2\n",
    "\n",
    "df['V1'] = np.sqrt((df['Head_x']-df['ShoulderMid_x'])**2\n",
    "                   +(df['Head_y']-df['ShoulderMid_y'])**2\n",
    "                   +(df['Head_z']-df['ShoulderMid_z'])**2)\n",
    "\n",
    "df['ElbowMid_x'] = (df['ElbowLeft_x']+df['ElbowRight_x'])/2\n",
    "df['ElbowMid_y'] = (df['ElbowLeft_y']+df['ElbowRight_y'])/2\n",
    "df['ElbowMid_z'] = (df['ElbowLeft_z']+df['ElbowRight_z'])/2\n",
    "\n",
    "df['V2'] = np.sqrt((df['ShoulderMid_x']-df['ElbowMid_x'])**2\n",
    "                   +(df['ShoulderMid_y']-df['ElbowMid_y'])**2\n",
    "                   +(df['ShoulderMid_z']-df['ElbowMid_z'])**2)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'othereight', 'otherone', 'dan', 'carlie', 'otherfour', 'liz', 'pat', 'zoe', 'sue', 'othertwo', 'billy', 'mia', 'ben', 'meg', 'lucia', 'tonya', 'name', 'kim', 'ken', 'otherfive', 'otherseven', 'othersix', 'bea', 'eva', 'andreas', 'sammie', 'otherthree', 'yanni', 'ann', 'amy', 'noe', 'ryan', 'ron'}\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "# number of students\n",
    "\n",
    "namelist = set(df['weighted_name'])\n",
    "print(namelist)\n",
    "\n",
    "n = len(namelist)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data for model fitting\n",
    "\n",
    "df_fit = df[['H1','H2','V1','V2','weighted_name']]\n",
    "df_fit.head()\n",
    "X = df_fit[['H1','H2','V1','V2']].values\n",
    "y = df_fit['weighted_name'].values\n",
    "dummy_y = pd.get_dummies(df_fit['weighted_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3280579305850718\n",
      "0.279255807596537\n",
      "[[2881  117   30 ...    2  153   30]\n",
      " [  82 1157   46 ...    0  343   44]\n",
      " [  36   79  915 ...    2  111   20]\n",
      " ...\n",
      " [   4    7    4 ...   34   22    2]\n",
      " [ 129  253   94 ...    1 2296   91]\n",
      " [  64   88   42 ...    0  286  498]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         amy       0.59      0.41      0.48      7097\n",
      "     andreas       0.21      0.16      0.19      7031\n",
      "         ann       0.36      0.24      0.29      3781\n",
      "         bea       0.24      0.06      0.10      1788\n",
      "         ben       0.22      0.18      0.20      8017\n",
      "       billy       0.31      0.37      0.34     15216\n",
      "      carlie       0.28      0.51      0.36     29614\n",
      "         dan       0.25      0.11      0.15      3971\n",
      "         eva       0.25      0.17      0.20     10490\n",
      "         ken       0.23      0.23      0.23      9375\n",
      "         kim       0.20      0.15      0.17     13888\n",
      "         liz       0.23      0.10      0.14      2797\n",
      "       lucia       0.18      0.03      0.06       743\n",
      "         meg       0.23      0.12      0.15      6239\n",
      "         mia       0.26      0.15      0.19      8707\n",
      "        name       0.25      0.44      0.32     32374\n",
      "         noe       0.25      0.15      0.19      9123\n",
      "  othereight       0.25      0.02      0.04       286\n",
      "   otherfive       0.00      0.00      0.00        10\n",
      "   otherfour       0.24      0.08      0.12       636\n",
      "    otherone       0.29      0.07      0.12       454\n",
      "  otherseven       0.26      0.06      0.09      2304\n",
      "    othersix       0.00      0.00      0.00         8\n",
      "  otherthree       0.38      0.45      0.41      1517\n",
      "    othertwo       0.36      0.05      0.08       352\n",
      "         pat       0.25      0.08      0.12      3875\n",
      "         ron       0.22      0.13      0.16     10589\n",
      "        ryan       0.87      0.72      0.79      3880\n",
      "      sammie       0.28      0.25      0.27     11980\n",
      "         sue       0.46      0.28      0.35      9373\n",
      "       tonya       0.39      0.08      0.13       437\n",
      "       yanni       0.22      0.19      0.20     12327\n",
      "         zoe       0.31      0.09      0.13      5854\n",
      "\n",
      "   micro avg       0.28      0.28      0.28    234133\n",
      "   macro avg       0.28      0.19      0.21    234133\n",
      "weighted avg       0.28      0.28      0.26    234133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Supervised: KNeighborsClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=n)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(knn.score(X_train, y_train))\n",
    "print(knn.score(X_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "390221/390221 [==============================] - 484s 1ms/step - loss: 2.7935 - acc: 0.2137\n",
      "390221/390221 [==============================] - 204s 524us/step\n",
      "Epoch 1/1\n",
      "390221/390221 [==============================] - 426s 1ms/step - loss: 2.8707 - acc: 0.1590\n",
      "390221/390221 [==============================] - 151s 386us/step\n",
      "Baseline: 14.16% (2.45%)\n"
     ]
    }
   ],
   "source": [
    "# Supervised: Deep Learning\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size = 0.3, random_state=42)\n",
    "\n",
    "\n",
    "n_cols = X_train.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "\n",
    "def baseline_model():\n",
    "    dl = Sequential()\n",
    "    dl.add(Dense(10, activation='relu', input_shape = input_shape))\n",
    "    dl.add(Dense(10, activation='relu'))\n",
    "    dl.add(Dense(n, activation='softmax'))\n",
    "    dl.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "    return dl\n",
    "\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=1, batch_size=1)\n",
    "\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=2)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
